# Importing Standard Libraries
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

# Load the dataset
auto = pd.read_csv("auto-mpg (1).csv")

# Check and clean data
auto['horsepower'] = pd.to_numeric(auto['horsepower'], errors='coerce')  # Convert 'horsepower' to numeric, coerce errors to NaN
auto.dropna(subset=['horsepower'], inplace=True)  # Drop rows with NaN values in 'horsepower'

# Selecting numeric columns for correlation
numeric_auto = auto.select_dtypes(include=['number'])

# Plot correlation heatmap
plt.figure(figsize=(8, 8))
sns.heatmap(numeric_auto.corr(), annot=True, cmap='coolwarm', linewidths=0.5)
plt.title('Correlation Heatmap')
plt.show()

# Feature selection
X = auto[['displacement', 'horsepower', 'acceleration', 'model year', 'origin']]
y = auto['mpg']

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=101)

# Create and train the model
lr = LinearRegression()
lr.fit(X_train, y_train)

# Make predictions
pred = lr.predict(X_test)

# Print evaluation metrics
print('Mean Absolute Error:', mean_absolute_error(y_test, pred))
print('Mean Squared Error:', mean_squared_error(y_test, pred))
print('Root Mean Squared Error:', np.sqrt(mean_squared_error(y_test, pred)))
print('Coefficient of Determination (R^2):', r2_score(y_test, pred))

# Print predicted vs actual value for a sample
print('Predicted fuel consumption (mpg):', pred[2])
print('Actual fuel consumption (mpg):', y_test.values[2])
